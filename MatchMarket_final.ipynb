{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MatchMarket_final",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNUUUQOFtruQXUNkALJ9EOi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FlorianMimolle/MatchMarket-final/blob/master/MatchMarket_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTrRw8e_idPK",
        "outputId": "9999ad2d-b966-4af5-b30c-f07fe98f7f64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_column(loc, value, pi)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:352: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:356: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:403: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:404: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:405: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:406: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:407: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:408: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:409: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:410: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:411: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:412: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:413: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:414: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ],
      "source": [
        "#Importation de librairies :\n",
        "import re\n",
        "import zipfile \n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics  import silhouette_score\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "df = pd.read_csv('20220201230731-all_campaigns.csv', sep=',')\n",
        "\n",
        "#Campagne : # Ajouter les campagnes_id au fur et à mesure que la table sera updatée\n",
        "def typeCampagne(numero):\n",
        "    cosmetique = [33,77]\n",
        "    deco = [8,20,43,76]\n",
        "    mode = [2,4,6,7,22,23,25,26,27,28,30,34,35,36,37,38,39,40,41,42,78]\n",
        "    #si le numéro est dans une des listes : il renvoie le mot correspondant à la campagne\n",
        "    if numero in cosmetique :\n",
        "        return \"Cosmetique\"\n",
        "    elif numero in deco:\n",
        "        return \"Deco\"\n",
        "    elif numero in mode:\n",
        "        return \"Mode\"\n",
        "\n",
        "#Liste des catégories :\n",
        "    #Matière : \n",
        "naturel = ['coton','lin','laine','cachemire','soie','caoutchouc','alpaga','cuir','chanvre','angora','tricotine', 'suède', \n",
        "            'raffia', 'métal', 'laiton', 'konjac', 'karité', 'jute', 'huiles', 'hêtre', 'daim', 'chèvre', 'chêne', 'bouleau',\n",
        "            'bois', 'aluminium', 'aluminium acier', 'acier', 'acier laqué', 'abeille', 'coco', 'huile', 'denim', 'dentelle',\n",
        "            'guipure', 'huiles', 'jersey', 'textile', 'tissu', 'toile', 'tweed', 'viscose']\n",
        "synthetique = ['acrylique', 'caoutchouc', 'cuir végétal','denim', 'dentelle', 'fausse fourrure', 'guipure',\n",
        "            'jersey','nylon','plastique','plexi','polyamide','polyester','polyurethane','polyuréthane', 'PU', \n",
        "            'PVC', 'stratifié', 'stratifié imprimé marbre', 'synthétique', 'textile', 'tissu', 'toile', 'tweed',\n",
        "            'vinyle', 'viscose', 'elasthanne']\n",
        "    #Label : \n",
        "ecolabel = ['gots','oeko-tex', 'oeko tex', 'naturleder','eu ecolabel','origine france garantie', 'eco tex','eco-tex',\n",
        "            'bio', 'recyclé', 'biologique', 'responsable', 'responsables', 'écoresponsable', 'éco-responsable',\n",
        "            'upcyclé', 'vegan', 'vegane']\n",
        "    #Couleurs:\n",
        "color_vif = ['multicolor','doré','argenté','bleu algue','bleu canard','bleu lagon','bleu turquoise','jaune',\n",
        "            'jaune clair','jaune pastel','jaune moutarde','jaune safran','marron terracotta','orange','rose',\n",
        "            'rose framboise','rose fuchsia','rouge','rouge corail','rouge brique','rouge cerise','vert',\n",
        "            'vert clair','vert menthe','vert olive','vert pistache','vert sapin','violet lavande',\n",
        "            'violet lila','fleurs','mauve','brun roux',\"vert d'eau\",'fuschia','parme','lila','lavande',\n",
        "            'moutarde','corail','safran','terrer de sienne','bandana rouge','touches multicolors',\n",
        "            \"menthe a   l'eau\",'rose multicolore','olive','rum punch','rose 77','schiap','unicorn',\n",
        "            'tie dye','rose 01','719 love bouquet','n92 rouge caftan','25 goldie red',\n",
        "            'n205 - fushia irresistible - fini mat lumineux','348 coral peony - satin','cerise n107',\n",
        "            'strawberry pink 02','pistache','mauve clair','lavande','jaune pastel','argenté clair','rose poudrée',\n",
        "            'imprimé géométique jaune','jaune tartan','rose rouge','terracotta','rose flash','algue']\n",
        "color_neutre = ['sans (transparent)','beige','beige sable','beige bouleau','beige camel','beige fauve','beige nude','beige chene','beige naturel',\n",
        "            'beige hetre','blanc','blanc cassé','bleu','bleu clair','bleu ciel','bleu pastel','bleu denim','bleu foncé','bleu profond',\n",
        "            'bleu klein','bleu marine','gris','gris clair','gris souris','gris foncé','gris taupe','marron',\n",
        "            'marron caramel','marron cognac','marron fauve','marron noisette','marron chocolat','noir','rose clair',\n",
        "            'rose saumon','rouge bordeaux','vert kaki','violet prune','fauvre','hêtre','bouleau',\n",
        "            'naturel','sable','léopard','jean','nude','bleu gris','bordeaux','ecru','noir délavé',\n",
        "            'camel','bleu délavé','bordeaux foncé','saumon','taupe','bandana fleur bleue','gris anthracite',\n",
        "            'bleu jean','croco marron','zèbre marron','cognac','matt','14 beige copacabana','brun nude 211',\n",
        "            'au naturel','marron camel','noir croco','noir semi-verni','marron croco','daim brun','brun',\n",
        "            'prune','noir blanc','blanc noir','noir beige','noir bleu','bleu blanc','bois clair','lin',\n",
        "            'marine']\n",
        "    #Style Préférence:\n",
        "style1 = ['casual', 'urbancool', 'streetwear']\n",
        "style2 = ['chic', 'smart', 'working girl']\n",
        "style3 = ['rock', 'gothique']\n",
        "style4 = ['engagée', 'made in france']\n",
        "style5 = ['fatale']\n",
        "style6 = ['bohême', 'romantique']\n",
        "style7 = ['vintage', 'kawaii']\n",
        "style8 = ['inconnu']\n",
        "    #Brand Preference:\n",
        "access_brand = [\"monoprix beauté\"]\n",
        "mass_brand = [\"sephora\",\"l'oréal\",\"nocibé\",\"maybelline\",\"bourjois\",\"marionnaud\",\"birchbox\",\"cosmopolitan\",\n",
        "            \"glossier\",\"mercu handy\",\"bleach london\"]\n",
        "premium_brand = [\"nuxe\",\"benefit cosmetics\",\"l'occitane\",\"origins\",\"black up\",\"bumble & bumble\",\"st tropez\",\n",
        "            \"les petits prodiges\",\"prescription lab\",\"mimitika\",\"claus porto\"]\n",
        "hdg_brand = [\"urban decay\",\"rituals\",\"nars\",\"opi\",\"kerastase\",\"essie\",\"bobbi brown\",\"payot\",\"aries\",\n",
        "            \"esthederm\",\"bkr\"]\n",
        "prestige_brand = [\"fenty beauty\",\"dior backstage\",\"kenzo\",\"lacoste\",\"clarins\",\"clinique\",\"huda beauty\",\n",
        "            \"burberry\",\"cacharel\",\"make up forever\",\"paco rabanne\",\"marc jacobs beauty\",\n",
        "            \"lolita lempicka\",\"erborian\",\"tom ford\",\"filorga\",\"talika\",\"molinard\"]\n",
        "luxe_brand = [\"chanel\", \"yves saint laurent\", \"lancome\", \"guerlain\", \"givenchy\", \"gucci\", \n",
        "            \"estée lauder\", \"nina ricci\", \"prada\", \"lancaster\", \"laneige\", \"sisley\", \"lanvin\", \n",
        "            \"la mer\", \"elizabeth arden\", \"acquia di parma\", \"la prairie\", \"issey miyake\", \n",
        "            \"juliette has a gun\", \"goutal\", \"shu uemura\", \"kilian\"]\n",
        "bio_brand = ['corine de farme','mademoiselle bio','sanoflore','cattier','havana','pur aloe',\n",
        "            'les fleurs de bach','egyptian magic','absolution','decleor','melvita','dr hauschka',\n",
        "            'herb essentials','abyssea','jonzac','akane','argiletz','lov organic','beliflor','leonor greyl',\n",
        "            'centifolia','florame','les huilettes','patyka','finessence','bivouak','les poulettes',\n",
        "            'lamazuna','pachamamai','greenma','oden','boulado','mamaki','kure bazaar','karethic']\n",
        "    #Mode Preference:\n",
        "access_mode = ['h&m', 'pimkie', 'pull&bear', 'asos', 'undiz', 'jennyfer', 'camaieu', 'c&a', 'kaporal', \n",
        "            'hollister', 'missguided', 'jack & jones', 'urban outfitters', 'vero moda', 'blancheporte', \n",
        "            'see u soon', 'stradivarius', 'shein', 'bershka', 'cache cache', 'boohoo', 'kiabi', 'bonobo', \n",
        "            'adopt', 'gemo', 'decathlon', 'la halle', 'bizzbee', 'la redoute', 'new look', 'monoprix']\n",
        "mass_mode = ['etam', 'adidas', 'zara', 'nike', \"levi's\", 'adidas originals', 'converse', 'etam lingerie', 'vans',\n",
        "            'zalando', 'puma', 'promod', 'naf naf', 'dr. martens', 'le coq sportif', 'fila', 'reebok', 'eastpak',\n",
        "            'teddy smith', 'asics', 'le temps des cerises', 'ikks', 'les tropéziennes', 'pepe jeans', 'champion',\n",
        "            'lancaster', 'quiksilver', 'lee cooper', 'kappa', 'princesse tam.tam', 'superdry', 'roxy', 'gap',\n",
        "            'birkenstock', 'rip curl', 'gambettes box', 'passionata', 'under armour', 'oysho', 'lookiero', \n",
        "            \"o'neill\", 'scotch & soda', 'steve madden', 'oakley', 'paul hewitt', 'juicy couture', 'superga', \n",
        "            'miss selfridge', 'blugirl', 'j.crew', 'speedo', 'thecloset', 'melissa', 'jj brands', 'mango', \n",
        "            'calzedonia', 'armand thierry', 'prettylittlething', 'dim', 'desigual', 'ange', 'courir', \n",
        "            'darjeeling', 'kookai', 'lollipops', 'american eagle', 'caroll', 'esprit', 'karl marc john', \n",
        "            'maison 123', 'new balance', 'ellesse tanker', 'armor-lux', 'crocs', 'eram', 'morgan', 'topshop', \n",
        "            'geox', 'okaidi', 'abercrombie', 'circus', 'swatch', 'jonak']\n",
        "premium_mode = ['calvin klein', 'lacoste', 'tommy hilfiger', 'diesel', 'michael kors', 'polo ralph lauren', \n",
        "            'zadig & voltaire', 'cacharel', 'karl lagerfeld', 'maje', 'the kooples', 'marc jacobs', 'ba&sh', \n",
        "            'sandro', 'petit bateau', 'love moschino', 'repetto', 'victoria beckham', 'pink', 'carhartt', \n",
        "            'sézane', 'porsche design', 'see by chloé', 'paul & joe', 'red valentino', 'bocage', 'dkny', \n",
        "            'gas bijoux', 'golden goose', 'le tanneur', 'claudie pierlot', 'bel air', 'liu jo', 'bazar deluxe',\n",
        "            'coach', 'coccinelle', 'furla', 'le mont st michel', 'hogan', 'veja', 'les petites', 'volcom',\n",
        "            'k-way', 'patagonia', 'fred perry', 'antik batik', 'j brands', \"marc o'polo\", 'berenice', \n",
        "            'reminiscence', 'ted baker', 'pinko', 'moon boot', 'ami paris', 'chiara ferragni', 'a.p.c.', \n",
        "            'colmar', 'stussy', 'bape', 'anne & valentin', 'la martina', \"l'eclaireur\", 'allsaints', \n",
        "            'bellerose', 'paige', 'kate spade', 'karen millen', 'iro', 'bally', \"church's\", 'asphalte',\n",
        "            'polène', 'etoile', 'from future', 'amen', 'charles jourdan', 'amélie pichard', 'tory burch', \n",
        "            'rouje', 'each x other', 'be blumarine', 'axel arigato', 'herschel supply co.', 'barbour', \n",
        "            'ancient greek sandals', 'mm6', 'notify', 'anine bing', 'jim rickey', 'belstaff', 'clergerie',\n",
        "            'zespa', 'kurt geiger', 'ambra maddalena', 'anya hindmarch', 'shourouk', 'house of holland',\n",
        "            'majestic filatures', 'aurelie bidermann', 'hogan rebel', 'vanessa seward', 'r.s.v.p.', \n",
        "            'charli cohen', 'falke', 'by malene birger', 'patrizia pepe', 'tosca blu', 'spanx', 'pandora', \n",
        "            'timberland', 'off-white', 'balzac', 'swarovski', 'camper', 'aubade', 'ash', 'ray-ban', 'g star',\n",
        "            'kiwi saint tropez', 'miss sixty', 'camperlab', 'banana moon', 'clarks', 'aigle', 'kickers', \n",
        "            'la jaquette', 'lululemon', 'ugg', 'christine laure', 'parisienne et alors', 'des petits hauts', \n",
        "            'free lance']\n",
        "hdg_mode = ['longchamp', 'kenzo', 'boss', 'hugo boss', 'the north face', 'giorgio armani', 'lancel', 'off white', \n",
        "            'canada goose', 'paul smith', 'acne studios', 'tom ford', 'max mara', 'la perla', 'vanessa bruno',\n",
        "            'cerruti 1881', 'moncler', 'sonia rykiel', 'escada', 'guy laroche', 'carolina herrera', \n",
        "            'agent provocateur', 'le petite robe di chiara boni', '7 for all mankind', 'alberta ferretti', \n",
        "            'plein sud', 'christopher kane', 'mcm', 'agnelle', 'akira naka', 'pyrenex', 'diane von furstenberg', \n",
        "            'alain mikli', 'agnona', 'raf simons', 'charlotte olympia', 'borsalino', 'zucca', 'barbara bui', \n",
        "            'k. jacques', 'jacomo', 'blumarine', 'paule ka', 'paul andrew', 'alexandra golovanoff', 'zac posen', \n",
        "            'botier', 'rag & bone', 'marni', 'olympia le-tan', 'jw anderson', 'fusalp', 'tom dixon', 'ambush', \n",
        "            'malo', 'harris wharf london', 'opening ceremony', 'msgm', 'sacai', 'etro', \n",
        "            'pleats please issey miyake', 'marlies dekkers', 'panoply', 'le gramme', 'tsumori chisato',\n",
        "            'equipment', 'theory', 'derek lam', 'smythson', 'sartore', 'vetements', 'aalto', 'isabel marant']\n",
        "prestige_mode = ['chloé', 'jean paul gaultier', 'burberry', 'christian louboutin', 'alexander mcqueen', 'versace',\n",
        "            'jacquemus', 'jimmy choo', 'cavalli', 'mugler', 'dsquared2', 'stella mccartney',\n",
        "            'giuseppe zanotti', 'alexander wang', 'issey miyake', 'roberto cavalli', '3.1 phillip lim',\n",
        "            'mulberry', 'rochas', 'vivienne westwood', 'salvatore ferragamo', 'sergio rossi', \n",
        "            'maison margiela', 'alexa chung', \"tod's\", 'baldinini', 'emilio pucci', 'missoni',\n",
        "            'alexandre vauthier', 'hervé leger', 'leonard', 'donna karan', 'yohji yamamoto', 'jil sander',\n",
        "            'brioni', 'rick owens', 'proenza schouler', 'nicholas kirkwood', 'ann demeulemeester', 'vanrycke',\n",
        "            'dice kayek']\n",
        "luxe_mode = ['chanel', 'dior', 'balenciaga', 'lous vuitton', 'gucci', 'hermès', 'givenchy', 'valentino', 'fendi', \n",
        "            'prada', 'saint laurent', 'balmain', 'céline', 'bvlgari', 'miu miu', 'van cleef & arpels',\n",
        "            'bottega veneta', 'elie saab', 'boucheron', 'pierre hardy', 'brunello cucinelli', 'loewe', \n",
        "            'zuhair murad', 'emanuel ungaro', 'ermenegildo zegna', 'maison ullens', 'pomellato', 'louis vuitton']\n",
        "vintage_mode = ['jean paul gaultier pre-owned', 'chanel pre-owned', 'rolex pre-owned', 'john galliano pre-owned',\n",
        "            'jc de castelbajac pre-owned', 'dries van noten pre-owned']\n",
        "eco_responsable_mode = ['stella mccartney', 'le chapeau', 'ganni', 'ekyog', 'hopaal', 'vanda jacintho', \n",
        "            'patagonia', 'alchemist', 'atelier unes', 're/done', \"n'go\", 'chaussettes orphelines',\n",
        "            '1083']\n",
        "\n",
        "#Fonctions : \n",
        "\n",
        "    #Pour Déterminer les coordonnées lat/Long en fonction du code postale : \n",
        "def coordonnées(code_postal):\n",
        "    if code_postal in coordonnées_dict :\n",
        "        return [coordonnées_dict[code_postal].split(\",\")[0],coordonnées_dict[code_postal].split(\",\")[1]]\n",
        "    else:\n",
        "        return None\n",
        "        \n",
        "    #Pour Déterminer le code INSEE en fonction du code postal : \n",
        "def codeInse(code_postal):\n",
        "    if str(code_postal) in codeinse_dict :\n",
        "        return codeinse_dict[str(code_postal)]\n",
        "    else:\n",
        "        return None\n",
        "    \n",
        "    #Pour Déterminer la population en fonction du code \n",
        "def Population(code_insee):\n",
        "    global liste \n",
        "    #Si le code INSEE est reconnu:\n",
        "    if str(code_insee) in density_dict :\n",
        "        #Si la population du village est suppérieur à 5000hab on met 1 (urbain)\n",
        "        if density_dict[str(code_insee)] > 5000:\n",
        "            return 1\n",
        "        #Sinon, On met 0 (rural)\n",
        "        else:\n",
        "            return 0 \n",
        "    #Si le code Insee est pas reconnu, c'est les arrondissements de villes, du coup, si les premiers chiffres sont 75,13 ou 69 on met urbain\n",
        "    elif (str(code_insee)[:2] == \"75\") | (str(code_insee)[:2] == \"13\") | (str(code_insee)[:2] == \"69\"):\n",
        "        return 1\n",
        "    #Sinon, on met rural par defaut\n",
        "    else:\n",
        "        return 0\n",
        "    \n",
        "    #Pour determiner le juste prix (en centimes):\n",
        "def Prix(price,campaign_id,product_id):\n",
        "    #Si la campaign est suppérieur à 20, les prix sont corrects sauf pour deux articles\n",
        "    if campaign_id >=20 :\n",
        "        if str(product_id) in [\"479\",\"181\"]:\n",
        "            return price*100\n",
        "        else:\n",
        "            return price\n",
        "    #Si la campaign id est inférieur à 20, on fait *100\n",
        "    else:\n",
        "        return price*100\n",
        "    \n",
        "    #Fonction pour compter les éléments d'une liste présent dans une autre liste : \n",
        "def compteur_additif(liste_df,liste_classeur):\n",
        "    compteur = 0\n",
        "    for i in list(liste_df): \n",
        "        if i.lower() in list(liste_classeur): #Si l'élement de la liste à tester est dans la liste_classeur alors on ajoute 1 au compteur\n",
        "            compteur += 1\n",
        "    return compteur\n",
        "\n",
        "    #Fonction pour déterminer si un element est dans une liste ou non :\n",
        "def compteur_unique(liste_df,liste_classeur):\n",
        "    compteur = 0\n",
        "    for i in liste_df:\n",
        "        if i.lower() in liste_classeur: #S'il y a des élements dans la liste à tester est dans la liste_classeur alors on renvoie 1\n",
        "            compteur = 1 \n",
        "    return compteur\n",
        "\n",
        "    #Créer deux fonctions pour répartir le prix dans la colonne like_price ou dislike_price en fonction de la colonne action\n",
        "def dislike(action_fact,valeur_colonne):\n",
        "    if action_fact == 1:\n",
        "        return valeur_colonne\n",
        "    else:\n",
        "        return 0\n",
        "def like(action_fact,valeur_colonne):\n",
        "    if action_fact == 0:\n",
        "        return valeur_colonne\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "    #Fonction pour déterminer le like_price globale\n",
        "def mean1(liste_price): #Like_price est la série du dataframe \n",
        "    somme=0\n",
        "    compte=0\n",
        "    moy = 0\n",
        "    for i in liste_price: #Pour tous les prix de la colonne, si le prix est différence de 0, alors on ajoute à la somme puis on fait la moyenne\n",
        "        if i >0:\n",
        "            somme +=i\n",
        "            compte+=1\n",
        "    if compte > 0:\n",
        "        moy=somme/compte\n",
        "    return moy  \n",
        "\n",
        "#On créé le Dictionnaire codePostale-coordonnées-code insee:\n",
        "r = requests.get(\"https://raw.githubusercontent.com/high54/Communes-France-JSON/master/france.json\")\n",
        "departement = pd.json_normalize(r.json())[[\"Code_postal\",\"coordonnees_gps\",\"Code_commune_INSEE\"]] #On récupère les données qui nous interesse du json\n",
        "departement[\"Code_postal\"] = departement[\"Code_postal\"].astype(str).apply(lambda x : \"0\" + x if len(x) ==4 else x) #On change le type pour qu'il prenne le 0 des codes postaux à 4 chiffres\n",
        "departement[\"Code_commune_INSEE\"] = departement[\"Code_commune_INSEE\"].astype(str).apply(lambda x : \"0\" + x if len(x) ==4 else x)\n",
        "departement = departement.set_index(\"Code_postal\")#On met le code postal en index\n",
        "departement = departement[departement[\"coordonnees_gps\"] != \"\"] #On supprime les données vides\n",
        "#On transforme les json nettoyés en dictionnaire :\n",
        "coordonnées_dict = departement.to_dict()[\"coordonnees_gps\"] \n",
        "codeinse_dict = departement.to_dict()[\"Code_commune_INSEE\"] \n",
        "r = requests.get(\"https://public.opendatasoft.com/explore/dataset/population-francaise-communes/download/?format=json&timezone=Europe/Berlin&lang=fr\")\n",
        "density = pd.json_normalize(r.json())\n",
        "density = density[[\"fields.annee_recensement\",\"fields.code_insee_commune\",\"fields.population_totale\"]] #On récupère les données du json qui nous interessent\n",
        "density = density.sort_values(by = \"fields.annee_recensement\", ascending = False).drop_duplicates(subset=[\"fields.code_insee_commune\"],keep = \"first\") #On garde l'année de resencement la plus récente lorsqu'il y a plusieurs années\n",
        "density = density.drop(columns = [\"fields.annee_recensement\"]) #On supprime la colonne année de recensement\n",
        "density = density.set_index(\"fields.code_insee_commune\") #On met le code insee en index pour transformer en dictionnaire\n",
        "density_dict = density.to_dict()[\"fields.population_totale\"]\n",
        "\n",
        "#Conversion des types de colonnes :\n",
        "df[\"birthdate\"] = pd.to_datetime(df[\"birthdate\"])\n",
        "df[\"zipcode\"] = df[\"zipcode\"].astype(str)\n",
        "#Remplacer les valeurs NaN par Incconu\n",
        "df['material'].fillna('Inconnu', inplace = True)\n",
        "df['zipcode'].fillna('Inconnu', inplace = True)\n",
        "df['styles preferences'].fillna('Inconnu', inplace = True)\n",
        "df['brands preferences'].fillna('Inconnu', inplace = True)\n",
        "df['fashion preferences'].fillna('Inconnu', inplace = True)\n",
        "#Supprimer les lignes/colonnes obseletes : \n",
        "    #email de test : \n",
        "df = df[(df['email']!='e@e.com') &\n",
        "        (df['email']!='aabiaad@netvariant.com') &\n",
        "        (df['email']!='ea7@test.com') &\n",
        "        (df['email']!='hello@praedicters.com') &\n",
        "        (df['email']!='slachats@yopmail.com')]\n",
        "df.dropna(subset = ['color'], inplace = True)  # Rediscuter si utile ou si remplacer par inconnu (puis ne pas mettre +1 au groupby)\n",
        "df.dropna(subset = ['price'], inplace = True)  # Rediscuter si utile ou si remplacer par inconnu (puis ne pas mettre +1 au groupby)\n",
        "df = df.drop(columns = [\"product reference\"])\n",
        "#Modification des valeurs abbérentes : \n",
        "    #Zipcode : \n",
        "df['zipcode'].replace('17 Ru', '56600', inplace=True) #Après vérification, 17 Ru correspond à une personne habitant en 56600\n",
        "df[\"zipcode\"] = df[\"zipcode\"].apply(lambda x : x.replace(\".0\",\"\")) #On enleve les .0 \n",
        "df['zipcode'].replace('1', '75', inplace=True) #Après vérification les personnes ayant mis 1 sont dans le 75\n",
        "df[\"zipcode\"] = df[\"zipcode\"].apply(lambda x : \"0\" + x if len(x) == 4 else #Ajoute un zéro pour les codes postaux à 4 chiffres\n",
        "                                                 x + \"001\" if x == 75 else #Attibue subjectivement le code postale 75001 à ceux qui n'ont mis que 75. (pour la suite, ils seront considérés comme urbain donc cela ne changera pas)\n",
        "                                          x[0:2]+\"000\" if len(x) == 3 else  #Attribue subjectivement le code préfécture pour les personnes ayant mis un code à 3 chiffres\n",
        "                                             x + \"000\" if len(x) == 2 else x) #Attribue subjectivement le code préfécture pour les personnes ayant mis un code à 2 chiffres\n",
        "    #Price : \n",
        "df[\"price\"] = np.vectorize(Prix)(df[\"price\"], df[\"campaign_id\"],df[\"product id\"]) #Calcule le prix en centime (en fonction de la campaign id et du product id)\n",
        "    #Matériaux remplace les mauvaises valeurs par les bonnes :\n",
        "searchfor = [',', ';', 'et', '&','%'] \n",
        "df_mixte = df[df['material'].str.contains('|'.join(searchfor))] \n",
        "df_unique = df[~df['material'].str.contains('|'.join(searchfor))]\n",
        "df_unique.loc[df_unique['material'].str.contains('coton',case=False),'material'] = 'Coton'\n",
        "df_unique.loc[df_unique['material'].str.contains('polyest', case=False), 'material'] = 'Polyester'\n",
        "df_unique.loc[df_unique['material'].str.contains('viscose', case=False),'material'] = 'Viscose'\n",
        "df_unique.loc[df_unique['material'].str.contains('soie', case=False),'material'] = 'Soie'\n",
        "df_unique.loc[df_unique['material'].str.contains('lin', case=False),'material'] = 'Lin'\n",
        "df_unique.loc[df_unique['material'].str.contains('cuir', case=False),'material'] = 'Cuir'\n",
        "df_unique.loc[df_unique['material'].str.contains('jean', case=False),'material'] = 'Jean'\n",
        "df_unique.loc[df_unique['material'].str.contains('toile', case=False),'material'] = 'Toile'\n",
        "df_unique.loc[df_unique['material'].str.contains('faille', case=False),'material'] = 'Maille'\n",
        "df_unique.loc[df_unique['material'].str.contains('maille', case=False),'material'] = 'Maille'\n",
        "df_unique.loc[df_unique['material'].str.contains('laine', case=False),'material'] = 'Laine'\n",
        "df_unique.loc[df_unique['material'].str.contains('lon', case=False),'material'] = 'Nylon'\n",
        "df_unique.loc[df_unique['material'].str.contains('tweed', case=False),'material'] = 'Tweed'\n",
        "df_unique.loc[df_unique['material'].str.contains('acrylique', case=False),'material'] = 'Acrylique'\n",
        "df_unique.loc[df_unique['material'].str.contains('bois', case=False),'material'] = 'Bois'\n",
        "df_unique.loc[df_unique['material'].str.contains('hêtre', case=False),'material'] = 'Hêtre'\n",
        "df_unique.loc[df_unique['material'].str.contains('pvc', case=False),'material'] = 'PVC'\n",
        "df_unique.loc[df_unique['material'].str.contains('tweed', case=False),'material'] = 'Tweed'\n",
        "df_unique.loc[df_unique['material'].str.contains('ra', case=False),'material'] = 'Raffia'\n",
        "df = pd.concat([df_unique,df_mixte])\n",
        "df['material'] = df['material'].apply(lambda x: re.sub('\\W+', ' ', x))\n",
        "df['material'] = df['material'].apply(lambda x: re.sub('\\d+', ' ', x))\n",
        "df['material'] = df['material'].apply(lambda x: x.replace('et ',''))\n",
        "df['material'] = df['material'].str.split()\n",
        "    #Couleur : remplace les mauvaises valeurs par les bonnes :\n",
        "df['color'] = df['color'].str.replace(' &',',')\n",
        "df['color'] = df['color'].str.replace(' et',',')\n",
        "df['color'] = df['color'].str.lower()\n",
        "df['color'] = df['color'].apply(lambda x: re.sub(\"\\s\\d+\",\"\",x))\n",
        "df['color'] = df['color'].str.replace('chêne','beige chene')\n",
        "df['color'] = df['color'].str.replace('noire','noir')\n",
        "df['color'] = df['color'].str.replace('verte','vert')\n",
        "df['color'] = df['color'].str.replace('mc','multicolor')\n",
        "df['color'] = df['color'].str.replace('fuchsia','fuschia')\n",
        "df['color'] = df['color'].str.replace(\"coral\",\"corail\")\n",
        "df['color'] = df['color'].str.replace('moutarde','jaune moutarde')\n",
        "df['color'] = df['color'].str.replace('touches multicolores','multicolor')\n",
        "df['color'] = df['color'].str.replace('zèbre marron','marron, blanc')\n",
        "df['color'] = df['color'].str.replace('zèbre','noir, blanc')\n",
        "df['color'] = df['color'].str.replace('fauve','beige fauve')\n",
        "df['color'] = df['color'].str.replace('bordeaux ','bordeaux')\n",
        "df['color'] = df['color'].str.replace('multicolore','multicolor')\n",
        "df['color'] = df['color'].str.replace('bicolore noir, écru','noir, écru')\n",
        "df['color'] = df['color'].str.replace(\"rouge noir\",\"rouge, noir\")\n",
        "df['color'] = df['color'].apply(lambda x: x.split(', '))\n",
        "    #Préférences : remplace les mauvaises valeurs par les bonnes : \n",
        "df['styles preferences'] = df['styles preferences'].apply(lambda x: x.replace(' , ', ', '))\n",
        "df['styles preferences'] = df['styles preferences'].apply(lambda x: x.split(', '))\n",
        "df['brands preferences'] = df['brands preferences'].str.replace('Make uo Forever','Make up Forever')\n",
        "df['brands preferences'] = df['brands preferences'].apply(lambda x: x.split(', '))\n",
        "df['fashion preferences'] = df['fashion preferences'].apply(lambda x: x.split(', '))\n",
        "df = df.reset_index()\n",
        "#Colonne Age : \n",
        "df['Age'] = df['birthdate'].apply(lambda x: (pd.datetime.now().year - x.year))\n",
        "df['Age'].fillna(df['Age'].median(), inplace=True)# remplacer les Nan dans la colonne Age par la moyenne\n",
        "df = df[df['Age'] >= 15]#Enlever les profils ayant moins de 15 ans\n",
        "#Création des colonnes supplémentaires nécessaires au Machine Learning (ou à la création de graphique) grâce aux fonctions créées :\n",
        "df[\"Département\"] = df[\"zipcode\"].apply(lambda x : x[:2])\n",
        "df[\"Coordonnées\"] = df[\"zipcode\"].apply(lambda x : coordonnées(x))\n",
        "df[\"CodeInsee\"] = df[\"zipcode\"].apply(lambda x : codeInse(x))\n",
        "df[\"Urbain\"] = df[\"CodeInsee\"].apply(lambda x : Population(x))\n",
        "df['action_fact'] = df[\"action\"].factorize()[0]\n",
        "df[\"Naturel\"] = df[\"material\"].apply(lambda x : compteur_unique(x,naturel))\n",
        "df[\"Synthetique\"] = df[\"material\"].apply(lambda x : compteur_unique(x,synthetique))\n",
        "df[\"Ecolabel\"] = df[\"material\"].apply(lambda x : compteur_unique(x,ecolabel))\n",
        "df[\"type_Campaign\"] = df[\"campaign_id\"].apply(lambda x : typeCampagne(x))\n",
        "df[\"vif\"] = df[\"color\"].apply(lambda x : compteur_unique(x,color_vif))\n",
        "df[\"neutre\"] = df[\"color\"].apply(lambda x : compteur_unique(x,color_neutre))\n",
        "df['Casual, Urbancool, Streetwear'] = df['styles preferences'].apply(lambda x: compteur_additif(x,style1))\n",
        "df['Chic, Smart, Working Girl'] = df['styles preferences'].apply(lambda x: compteur_additif(x,style2))\n",
        "df['Rock, Gothique'] = df['styles preferences'].apply(lambda x: compteur_additif(x,style3))\n",
        "df['Engagée, Made in France'] = df['styles preferences'].apply(lambda x: compteur_additif(x,style4))\n",
        "df['Fatale'] = df['styles preferences'].apply(lambda x: compteur_additif(x,style5))\n",
        "df['Bohême, Romantique'] = df['styles preferences'].apply(lambda x: compteur_additif(x,style6))\n",
        "df['Vintage, Kawaii'] = df['styles preferences'].apply(lambda x: compteur_additif(x,style7))\n",
        "df['Inconnu'] = df['styles preferences'].apply(lambda x: compteur_additif(x,style8))\n",
        "df[\"access_brand\"] = df[\"brands preferences\"].apply(lambda x : compteur_additif(x,access_brand))\n",
        "df[\"mass_brand\"] = df[\"brands preferences\"].apply(lambda x : compteur_additif(x,mass_brand))\n",
        "df[\"premium_brand\"] = df[\"brands preferences\"].apply(lambda x : compteur_additif(x,premium_brand))\n",
        "df[\"hdg_brand\"] = df[\"brands preferences\"].apply(lambda x : compteur_additif(x,hdg_brand))\n",
        "df[\"prestige_brand\"] = df[\"brands preferences\"].apply(lambda x : compteur_additif(x,prestige_brand))\n",
        "df[\"luxe_brand\"] = df[\"brands preferences\"].apply(lambda x : compteur_additif(x,luxe_brand))\n",
        "df[\"bio_brand\"] = df[\"brands preferences\"].apply(lambda x : compteur_additif(x,bio_brand))    \n",
        "df[\"access_mode\"] = df[\"fashion preferences\"].apply(lambda x : compteur_additif(x,access_mode))\n",
        "df[\"mass_mode\"] = df[\"fashion preferences\"].apply(lambda x : compteur_additif(x,mass_mode))\n",
        "df[\"premium_mode\"] = df[\"fashion preferences\"].apply(lambda x : compteur_additif(x,premium_mode))\n",
        "df[\"hdg_mode\"] = df[\"fashion preferences\"].apply(lambda x : compteur_additif(x,hdg_mode))\n",
        "df[\"prestige_mode\"] = df[\"fashion preferences\"].apply(lambda x : compteur_additif(x,prestige_mode))\n",
        "df[\"luxe_mode\"] = df[\"fashion preferences\"].apply(lambda x : compteur_additif(x,luxe_mode))\n",
        "df[\"vintage_mode\"] = df[\"fashion preferences\"].apply(lambda x : compteur_additif(x,vintage_mode))\n",
        "df[\"eco_responsable_mode\"] = df[\"fashion preferences\"].apply(lambda x : compteur_additif(x,eco_responsable_mode))\n",
        "\n",
        "#Remettre en ordre les colonnes\n",
        "df_ML = df[[\"user id\",\"Age\",\"Urbain\",\n",
        "            \"Casual, Urbancool, Streetwear\",\"Chic, Smart, Working Girl\",\"Rock, Gothique\",\"Engagée, Made in France\",\"Fatale\",\"Bohême, Romantique\",\"Vintage, Kawaii\",\"Inconnu\",\n",
        "            \"access_brand\",\"mass_brand\",\"premium_brand\",\"hdg_brand\",\"prestige_brand\",\"luxe_brand\",\"bio_brand\",\n",
        "            \"access_mode\", \"mass_mode\", \"premium_mode\", \"hdg_mode\", \"prestige_mode\", \"luxe_mode\", \"vintage_mode\", \"eco_responsable_mode\", \n",
        "            \"action_fact\",\n",
        "            \"type_Campaign\",\n",
        "            \"price\",\n",
        "            \"Naturel\",\"Synthetique\",\n",
        "            \"Ecolabel\",\n",
        "            \"vif\",\"neutre\"]]\n",
        "#Créer les colonnes like/dislike en fonction du prix, matière et couleur\n",
        "df_ML[\"like_price\"] = np.vectorize(like)(df_ML[\"action_fact\"], df_ML[\"price\"])\n",
        "df_ML[\"dislike_price\"] = np.vectorize(dislike)(df_ML[\"action_fact\"], df_ML[\"price\"])\n",
        "df_ML[\"like_Naturel\"] = np.vectorize(like)(df_ML[\"action_fact\"], df_ML[\"Naturel\"])\n",
        "df_ML[\"dislike_Naturel\"] = np.vectorize(dislike)(df_ML[\"action_fact\"], df_ML[\"Naturel\"])\n",
        "df_ML[\"like_Synthetique\"] = np.vectorize(like)(df_ML[\"action_fact\"], df_ML[\"Synthetique\"])\n",
        "df_ML[\"dislike_Synthetique\"] = np.vectorize(dislike)(df_ML[\"action_fact\"], df_ML[\"Synthetique\"])\n",
        "df_ML[\"like_Ecolabel\"] = np.vectorize(like)(df_ML[\"action_fact\"], df_ML[\"Ecolabel\"])\n",
        "df_ML[\"dislike_Ecolabel\"] = np.vectorize(dislike)(df_ML[\"action_fact\"], df_ML[\"Ecolabel\"])\n",
        "df_ML[\"like_vif\"] = np.vectorize(like)(df_ML[\"action_fact\"], df_ML[\"vif\"])\n",
        "df_ML[\"dislike_vif\"] = np.vectorize(dislike)(df_ML[\"action_fact\"], df_ML[\"vif\"])\n",
        "df_ML[\"like_neutre\"] = np.vectorize(like)(df_ML[\"action_fact\"], df_ML[\"neutre\"])\n",
        "df_ML[\"dislike_neutre\"] = np.vectorize(dislike)(df_ML[\"action_fact\"], df_ML[\"neutre\"])\n",
        "# Supprime les colonnes d'origines\n",
        "df_ML = df_ML.drop(columns = [\"action_fact\",\"price\",\"Naturel\",\"Synthetique\",\"Ecolabel\",\"vif\",\"neutre\"])\n",
        "# Séparer les df en fonction de différentes types de campagnes\n",
        "df_ML_Deco = df_ML[df_ML[\"type_Campaign\"] == \"Deco\"].drop(columns = [\"type_Campaign\"])\n",
        "df_ML_Cosme = df_ML[df_ML[\"type_Campaign\"] == \"Cosmetique\"].drop(columns = [\"type_Campaign\"])\n",
        "df_ML_Fashion = df_ML[df_ML[\"type_Campaign\"] == \"Mode\"].drop(columns = [\"type_Campaign\"])\n",
        "\n",
        "##############BOUCLE MACHINE LEARNING CLUSTERING ################################: \n",
        "nom_df = [\"Fashion\",\"Deco\",\"Cosmetique\"]\n",
        "compteur = 0 #Le compteur nous permet de nommer le fichier i correctement\n",
        "for df_ML_i in [df_ML_Fashion,df_ML_Deco,df_ML_Cosme]: #On clusterise chaque df_type_campaign ; \n",
        "    #On regroupe chaque lignes appartenant au même client pour avoir une ligne par client : \n",
        "    df_ML_i = df_ML_i.groupby(\"user id\").agg({\"Age\" : \"first\", #Pour les données spécifiques au client (qui se repète sur chaque ligne de vote) : on garde la première valeurs \n",
        "                                                \"Urbain\" : \"first\",\n",
        "                                                \"Casual, Urbancool, Streetwear\" : \"first\",\n",
        "                                                \"Chic, Smart, Working Girl\" : \"first\",\n",
        "                                                \"Rock, Gothique\" : \"first\",\n",
        "                                                \"Engagée, Made in France\" : \"first\",\n",
        "                                                \"Fatale\" : \"first\",\n",
        "                                                \"Bohême, Romantique\" : \"first\",\n",
        "                                                \"Vintage, Kawaii\" : \"first\",\n",
        "                                                \"Inconnu\": \"first\",\n",
        "                                                \"access_brand\": \"first\",\n",
        "                                                \"mass_brand\": \"first\",\n",
        "                                                \"premium_brand\": \"first\",\n",
        "                                                \"hdg_brand\": \"first\",\n",
        "                                                \"prestige_brand\":\"first\",\n",
        "                                                \"luxe_brand\": \"first\",          \n",
        "                                                \"bio_brand\": \"first\", \n",
        "                                                \"access_mode\": \"first\",\n",
        "                                                \"mass_mode\": \"first\",\n",
        "                                                \"premium_mode\": \"first\",\n",
        "                                                \"hdg_mode\": \"first\",\n",
        "                                                \"prestige_mode\": \"first\",\n",
        "                                                \"luxe_mode\": \"first\",\n",
        "                                                \"vintage_mode\": \"first\",\n",
        "                                                \"eco_responsable_mode\": \"first\",\n",
        "                                                \"like_price\" : mean1, #Pour les lignes de prix, on moyenne les prix suppérieur à 0\n",
        "                                                \"dislike_price\" : mean1,\n",
        "                                                \"like_Naturel\" : \"sum\", #Pour les lignes concernant les votes, on compte pour avoir le nombre de vote like/dislike du clients par critères\n",
        "                                                \"dislike_Naturel\" : \"sum\",\n",
        "                                                \"like_Synthetique\" : \"sum\",\n",
        "                                                \"dislike_Synthetique\" : \"sum\",\n",
        "                                                \"like_Ecolabel\" : \"sum\",\n",
        "                                                \"dislike_Ecolabel\" : \"sum\",\n",
        "                                                \"like_vif\" : \"sum\",\n",
        "                                                \"dislike_vif\" : \"sum\",\n",
        "                                                \"like_neutre\":\"sum\",\n",
        "                                                \"dislike_neutre\" : \"sum\"})\n",
        "    #On créé un copie du df_ML_i pour scaller sur cette copie (et garder en mémoire les vrais valeurs)\n",
        "    df_ML_i_scale = df_ML_i.copy()\n",
        "    #On scale les colonnes avec Robust Scaler (car il y a des outliers)\n",
        "    rb_scaler = RobustScaler() \n",
        "    df_ML_i_scale['Age'], \\\n",
        "    df_ML_i_scale['Casual, Urbancool, Streetwear'], \\\n",
        "    df_ML_i_scale['Chic, Smart, Working Girl'], \\\n",
        "    df_ML_i_scale['Rock, Gothique'], \\\n",
        "    df_ML_i_scale['Engagée, Made in France'], \\\n",
        "    df_ML_i_scale['Fatale'], \\\n",
        "    df_ML_i_scale['Bohême, Romantique'], \\\n",
        "    df_ML_i_scale['Vintage, Kawaii'], \\\n",
        "    df_ML_i_scale['Inconnu'], \\\n",
        "    df_ML_i_scale['access_brand'],\\\n",
        "    df_ML_i_scale['mass_brand'],\\\n",
        "    df_ML_i_scale['premium_brand'],\\\n",
        "    df_ML_i_scale['hdg_brand'],\\\n",
        "    df_ML_i_scale['prestige_brand'],\\\n",
        "    df_ML_i_scale['luxe_brand'],\\\n",
        "    df_ML_i_scale['bio_brand'],\\\n",
        "    df_ML_i_scale['access_mode'],\\\n",
        "    df_ML_i_scale['mass_mode'],\\\n",
        "    df_ML_i_scale['premium_mode'],\\\n",
        "    df_ML_i_scale['hdg_mode'],\\\n",
        "    df_ML_i_scale['prestige_mode'],\\\n",
        "    df_ML_i_scale['luxe_mode'],\\\n",
        "    df_ML_i_scale['vintage_mode'],\\\n",
        "    df_ML_i_scale['eco_responsable_mode'],\\\n",
        "    df_ML_i_scale['like_price'], \\\n",
        "    df_ML_i_scale['dislike_price'], \\\n",
        "    df_ML_i_scale['like_Naturel'], \\\n",
        "    df_ML_i_scale['dislike_Naturel'], \\\n",
        "    df_ML_i_scale['like_Synthetique'], \\\n",
        "    df_ML_i_scale['dislike_Synthetique'], \\\n",
        "    df_ML_i_scale['like_Ecolabel'], \\\n",
        "    df_ML_i_scale['dislike_Ecolabel'], \\\n",
        "    df_ML_i_scale['like_vif'], \\\n",
        "    df_ML_i_scale['dislike_vif'], \\\n",
        "    df_ML_i_scale['like_neutre'], \\\n",
        "    df_ML_i_scale['dislike_neutre'] = rb_scaler.fit_transform(df_ML_i_scale[[\"Age\",\n",
        "                                                                               \"Casual, Urbancool, Streetwear\",\n",
        "                                                                               \"Chic, Smart, Working Girl\",\n",
        "                                                                               \"Rock, Gothique\",\n",
        "                                                                               \"Engagée, Made in France\",\n",
        "                                                                               \"Fatale\",\n",
        "                                                                               \"Bohême, Romantique\",\n",
        "                                                                               \"Vintage, Kawaii\",\n",
        "                                                                               \"Inconnu\",\n",
        "                                                                                \"access_brand\",\n",
        "                                                                                \"mass_brand\",\n",
        "                                                                                \"premium_brand\",\n",
        "                                                                                \"hdg_brand\",\n",
        "                                                                                \"prestige_brand\",\n",
        "                                                                                \"luxe_brand\",          \n",
        "                                                                                \"bio_brand\",  \n",
        "                                                                               \"access_mode\",\n",
        "                                                                               'mass_mode',\n",
        "                                                                               'premium_mode',\n",
        "                                                                               'hdg_mode',\n",
        "                                                                               'prestige_mode',\n",
        "                                                                               'luxe_mode',\n",
        "                                                                               'vintage_mode',\n",
        "                                                                                'eco_responsable_mode',\n",
        "                                                                                \"like_price\",\n",
        "                                                                                \"dislike_price\",\n",
        "                                                                                \"like_Naturel\",\n",
        "                                                                                \"dislike_Naturel\",\n",
        "                                                                                \"like_Synthetique\",\n",
        "                                                                                \"dislike_Synthetique\",\n",
        "                                                                                \"like_Ecolabel\",\n",
        "                                                                                \"dislike_Ecolabel\",\n",
        "                                                                                \"like_vif\",\n",
        "                                                                                \"dislike_vif\",\n",
        "                                                                                \"like_neutre\",\n",
        "                                                                                \"dislike_neutre\"]]).T\n",
        "    # Principal Composant Analysis (PCA) :\n",
        "    # Faire du PCA pour réduire le nombre de colonnes et enlever les corrélations avant de faire du clustering pour améliorer le modèle\n",
        "    pca = PCA(n_components = 0.95) #On indique que l'on souhaite réduire le nombre de colonne mais en gardant 95% de l'information initiale\n",
        "    X_pca = pca.fit_transform(df_ML_i_scale) #On scale les données\n",
        "    #Methode de la silhouette pour déterminer le nombre de cluster idéal : \n",
        "    #Le nombre de cluster idéal est obtenue pour le score_silhouette maximal : \n",
        "    max_score = 0 #Au départ on fixe le score max à 0\n",
        "    k_max = 0 #et donc le nombre de cluster (k) idéal est à 0 au début\n",
        "    for k in range(3,10): #On teste tout les k entre 3 et 10 (si on met 2, la silhouette determinera probablement deux clusters idéales : un gros et un rassemblant les outliers.. )\n",
        "        model = KMeans(n_clusters=k).fit(X_pca) #On entraine le model\n",
        "        if silhouette_score(X_pca, model.labels_) > max_score: #Si le score avec le k testé à ce tour est supérieur au score_max (au premier tour il le sera forcement)\n",
        "            max_score = silhouette_score(X_pca, model.labels_) #Alors le score_max prend la valeur du score obtenue à ce tour\n",
        "            k_max = k #Et le k_max devient le k testé à ce tour\n",
        "    # 4 cluster semblent idéaux pour faire du clustering\n",
        "    model_max = KMeans(n_clusters=k_max).fit(X_pca) #On entraine le modèle avec le k_max trouvé\n",
        "    y = model_max.fit_predict(X_pca) #On determine les clusters avec le modèle entrainé\n",
        "    df_ML_i[\"cluster\"] = y #On rajoute de la colonne cluster dans le dataframe avant le scale\n",
        "    df_ML_i['cluster'] = df_ML_i['cluster'].apply(lambda x: x+1)#On ajoute +1 au numéro de cluster (pour plus de lisibilité, le cluster 0 devient le cluster 1)\n",
        "    \n",
        "    df_ML_i.to_csv(f'{nom_df[compteur]}.csv') #On génère le csv obtenu\n",
        "    compteur +=1 #Ajoute 1 au compteur créé au début du machine learning pour la gestion du nom du fichier\n",
        "\n",
        "#Créé le dataframe utilisé pour faire les graphiques\n",
        "df = df[['campaign_id','action','product name','color','material','user id','zipcode','Age','Département','Coordonnées','Urbain','vif','neutre','Naturel','Synthetique','type_Campaign']]\n",
        "df.to_csv('df.csv.zip', index = False, compression = \"zip\")"
      ]
    }
  ]
}